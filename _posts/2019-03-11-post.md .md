---
title: "PR&ML N Dimension Vs. D Dimension Notation"
date: 2019-03-11 23:02:00 -0400
categories: ML PRML
---


PR&ML(Pattern Recognition and Machine Learning) by Christopher M. Bishop
_____________________________


PR&ML을 공부하면서, 개인적으로 헷갈리는 내용을 정리하였다.

현재까지 지도학습, 비지도학습 내용을 한 번 보긴 했지만, 내용중에는 많이 나오지만

특히나 이해가 안가는 부분은 차원(Dimension)에 관한 내용이다.




서론에 나오는 **수학적 표기법**에 관한 내용으로

차원 수 N을 가지는 **x**와 차원수 D를 가지는 x 두 가지 표현 방식이 다르게 나타나 있다.

(위 기호 들은 Vector이며, Scalar는 *x*로 표기)




차원 수 N을 가지는 **x**는 일차원 Variable 즉, Scalar의 값을 한번에 묶어서 Vector로 표현하고자 사용한 것이다.

ex) *x*1=3.5, *x*2=1, *x*3=2, *x*4=10, *x*5=30 ㅡ> x1=[3.5, 1, 2, 10, 30]

위 예시와 같이 Scalar 값을  묶어서 Vector로 표현하면 변수를 많이 사용하지 않아도 된다는 편리함이 존재한다.




차원 수 D를 가지는 x는 단순히 차원을 표현하는 Vector이다.

즉, 1차원 변수, 2차원 변수, 3차원 변수 등에 따라 이를 표현하는 공간 또한 달라진다고 보면 된다.




차원 수 N과 차원 수 D를 가지는 두 Vector를 비교하면, 본질적인 것은 차원 수 N을 가지는 벡터는

Scalar를 묶어서 Vector로 표현 한 것이며, 차원 수 D는 본래부터 해당 차원의 한 점이었다고 생각하면 된다.




차원 수 D의 대해서, 차원 수 N Vector 형성과정 같이 예시를 하나 들자면,

3차원 Vector 데이터가 4개 모인다면, 이를 Matrix 형태로 합쳐서 Matrix로 형성할 수 있는데,
ex) N X D or D X N 으로 표현 가능. 그러므로 N차원 벡터의 D개, D차원 벡터의 N개로 표현 가능

이 때는 12(3x4=12)차원의 한 점으로 볼 수 있다.

MNIST 손글씨 이미지로 추가 예시를 들면,
Feed Foward Neural Network로 학습시키기 위해서
28x28 픽셀의 이미지를 784x1 데이터로 변환시켜서 학습을 시키는데,

이는 28차원의 데이터가 28개가 합쳐져서 Matrix로 된 것으로도 볼 수 있고

(하지만, 이미지는 본래 Matrix로 나오기 때문에 위 예시에 빗대어 설명을 한 것이지 중요하지 않다.)

해당 데이터를 784차원의 한 점으로 나타냈다고 볼 수 있다.




또한, 위에서 언급한 차원들은 Python에서 쓰이는 차원 얘기와 다르다.

Python에서의 1차원-Vector, 2차원-Matrix, 3차원 등등.... Rank=Dimension 개념으로 쓰이는 것이다.
